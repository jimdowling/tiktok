{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877c805b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Build Index </span>\n",
    "\n",
    "In this notebook you will create a feature group for your candidate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c73384",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de52446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16d07e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9577ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/11383\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e31c6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üéØ Compute Candidate Embeddings </span>\n",
    "\n",
    "You start by computing candidate embeddings for all items in the training data.\n",
    "\n",
    "First, you load your candidate model. Recall that you uploaded it to the Hopsworks Model Registry in the previous notebook. If you don't have the model locally you can download it from the Model Registry using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e88fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (2 dirs, 7 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "model = mr.get_model(\n",
    "    name=\"candidate_model\",\n",
    "    version=1,\n",
    ")\n",
    "model_path = model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dccd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec603fb",
   "metadata": {},
   "source": [
    "Next you compute the embeddings of all candidate videos that were used to train the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b25479",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name=\"retrieval\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9dc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (39.57s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `8`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2877-12-0444</td>\n",
       "      <td>RG876M</td>\n",
       "      <td>Female</td>\n",
       "      <td>76</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>6ZY07Y</td>\n",
       "      <td>News</td>\n",
       "      <td>192408</td>\n",
       "      <td>91932</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4380-37-7971</td>\n",
       "      <td>YU710V</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>5ZY75O</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7275</td>\n",
       "      <td>5936</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3714-23-7897</td>\n",
       "      <td>IQ911P</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>6NE41R</td>\n",
       "      <td>Dance</td>\n",
       "      <td>66149</td>\n",
       "      <td>45789</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age       country video_id category   views  \\\n",
       "0   2877-12-0444  RG876M  Female   76  South Africa   6ZY07Y     News  192408   \n",
       "1   4380-37-7971  YU710V  Female   59        Gambia   5ZY75O   Comedy    7275   \n",
       "2   3714-23-7897  IQ911P    Male   35         Sudan   6NE41R    Dance   66149   \n",
       "\n",
       "   likes  video_length  \n",
       "0  91932           113  \n",
       "1   5936           171  \n",
       "2  45789           238  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf72c728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ZY07Y</td>\n",
       "      <td>News</td>\n",
       "      <td>192408</td>\n",
       "      <td>91932</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ZY75O</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7275</td>\n",
       "      <td>5936</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6NE41R</td>\n",
       "      <td>Dance</td>\n",
       "      <td>66149</td>\n",
       "      <td>45789</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id category   views  likes  video_length\n",
       "0   6ZY07Y     News  192408  91932           113\n",
       "1   5ZY75O   Comedy    7275   5936           171\n",
       "2   6NE41R    Dance   66149  45789           238"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of input features for the candidate model from the model schema\n",
    "model_schema = model.model_schema['input_schema']['columnar_schema']\n",
    "candidate_features = [feat['name'] for feat in model_schema]\n",
    "\n",
    "# Select the candidate features from the training DataFrame\n",
    "item_df = train_df[candidate_features]\n",
    "\n",
    "# Drop duplicate rows based on the 'article_id' column to get unique candidate items\n",
    "item_df.drop_duplicates(subset=\"video_id\", inplace=True)\n",
    "\n",
    "item_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a8d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the item DataFrame\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    {col: item_df[col] for col in item_df})\n",
    "\n",
    "# Compute embeddings for all candidate items using the candidate_model\n",
    "candidate_embeddings = item_ds.batch(2048).map(\n",
    "    lambda x: (x[\"video_id\"], candidate_model(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b95ca",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Data Preparation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d30dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all article IDs and embeddings from the candidate_embeddings dataset\n",
    "all_article_ids = tf.concat([batch[0] for batch in candidate_embeddings], axis=0)\n",
    "all_embeddings = tf.concat([batch[1] for batch in candidate_embeddings], axis=0)\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "all_article_ids_np = all_article_ids.numpy()\n",
    "all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "items_ids_list = all_article_ids_np.tolist()\n",
    "embeddings_list = all_embeddings_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c311309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ZY07Y</td>\n",
       "      <td>[1.2281079292297363, 1.768419623374939, 0.7509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ZY75O</td>\n",
       "      <td>[1.2281079292297363, 1.768419623374939, 0.7509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6NE41R</td>\n",
       "      <td>[1.2281079292297363, 1.768419623374939, 0.7509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2OL92N</td>\n",
       "      <td>[11.753347396850586, -11.14534854888916, 4.464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0MH71C</td>\n",
       "      <td>[1.2281079292297363, 1.768419623374939, 0.7509...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id                                         embeddings\n",
       "0   6ZY07Y  [1.2281079292297363, 1.768419623374939, 0.7509...\n",
       "1   5ZY75O  [1.2281079292297363, 1.768419623374939, 0.7509...\n",
       "2   6NE41R  [1.2281079292297363, 1.768419623374939, 0.7509...\n",
       "3   2OL92N  [11.753347396850586, -11.14534854888916, 4.464...\n",
       "4   0MH71C  [1.2281079292297363, 1.768419623374939, 0.7509..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data_emb = pd.DataFrame({\n",
    "    'video_id': items_ids_list, \n",
    "    'embeddings': embeddings_list,\n",
    "})\n",
    "data_emb['video_id'] = data_emb['video_id'].str.decode('utf-8')\n",
    "\n",
    "data_emb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b6dfc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature Group Creation </span>\n",
    "\n",
    "Now you are ready to create a feature group for your candidate embeddings.\n",
    "\n",
    "To begin with, you need to create your Embedding Index where you will specify the name of the embeddings feature and the embeddings length.\n",
    "Then you attach this index to the FG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c3da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "emb = embedding.EmbeddingIndex()\n",
    "\n",
    "emb.add_embedding(\n",
    "    \"embeddings\",                           # Embeddings feature name\n",
    "    len(data_emb[\"embeddings\"].iloc[0]),    # Embeddings length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20644b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://snurran.hops.works/p/11383/fs/11331/fg/12305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ee9f1940eb41d2a69ac232a2ec223a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/24990 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: candidate_embeddings_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/11383/jobs/named/candidate_embeddings_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fe787503460>, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings_fg' feature group\n",
    "candidate_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"candidate_embeddings_fg\",\n",
    "    embedding_index=emb,                    # Specify the Embedding Index\n",
    "    primary_key=['video_id'],\n",
    "    version=1,\n",
    "    description='Embeddings for each video',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "candidate_embeddings_fg.insert(data_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d7f1a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1a3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://snurran.hops.works/p/11383/fs/11331/fv/candidate_embeddings/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"candidate_embeddings\",\n",
    "    version=1,\n",
    "    description='Embeddings of each article',\n",
    "    query=candidate_embeddings_fg.select([\"video_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25aae0",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "At this point you have a recommender system that is able to generate a set of candidate videos for a user. However, many of these could be poor, as the candidate model was trained with only a few subset of the features. In the next notebook, you'll create a ranking dataset to train a *ranking model* to do more fine-grained predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f53a397",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üß¨ Train Retrieval Model </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa182c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d80acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09283b4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b4ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/17565\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261b352",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üî™ Feature Selection </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c149d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_fg = fs.get_feature_group(\n",
    "    name=\"users\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "videos_fg = fs.get_feature_group(\n",
    "    name=\"videos\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "interactions_fg = fs.get_feature_group(\n",
    "    name=\"interactions\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c14e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272dc061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>watch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7133-34-1966</td>\n",
       "      <td>like</td>\n",
       "      <td>WA546S</td>\n",
       "      <td>3EL60S</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id interaction_type user_id video_id  watch_time\n",
       "0   7133-34-1966             like  WA546S   3EL60S         206"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generic = Generic(locale=Locale.EN)\n",
    "\n",
    "# obs = pd.DataFrame(\n",
    "#     [[generic.person.identifier(mask='####-##-####'), 'like', 'WA546S', '3EL60S', 206]],\n",
    "#     columns=['interaction_id', 'interaction_type', 'user_id', 'video_id', 'watch_time']\n",
    "# )\n",
    "# interactions_fg.insert(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a22d99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d72398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FEATURES = [\"user_id\", \"gender\", \"age\", \"country\"]\n",
    "CANDIDATE_FEATURES = [\"video_id\", \"category\", \"views\", \"likes\", \"video_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f091291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features = interactions_fg.select([\"interaction_id\"])\\\n",
    "    .join(users_fg.select(QUERY_FEATURES), on=\"user_id\")\\\n",
    "    .join(videos_fg.select(CANDIDATE_FEATURES), on=\"video_id\")\n",
    "\n",
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707f44",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af97a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/17565/fs/17485/fv/retrieval/version/1\n"
     ]
    }
   ],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='retrieval',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1dc1f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "437f3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arrow/cpp/src/arrow/status.cc:137: DoAction result was not fully consumed: Cancelled: Flight cancelled call, with message: CANCELLED. Detail: Cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (78.11s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8493-35-9872</td>\n",
       "      <td>MG666N</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>Turks &amp; Caicos Islands</td>\n",
       "      <td>0IE39E</td>\n",
       "      <td>News</td>\n",
       "      <td>63950</td>\n",
       "      <td>45996</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247-11-6324</td>\n",
       "      <td>IW619V</td>\n",
       "      <td>Other</td>\n",
       "      <td>44</td>\n",
       "      <td>C√¥te d‚ÄôIvoire</td>\n",
       "      <td>2PV16N</td>\n",
       "      <td>Technology</td>\n",
       "      <td>200516</td>\n",
       "      <td>144355</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0336-88-6412</td>\n",
       "      <td>EO571D</td>\n",
       "      <td>Other</td>\n",
       "      <td>34</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>9WK73L</td>\n",
       "      <td>News</td>\n",
       "      <td>181915</td>\n",
       "      <td>59220</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age                 country video_id  \\\n",
       "0   8493-35-9872  MG666N  Female   47  Turks & Caicos Islands   0IE39E   \n",
       "1   1247-11-6324  IW619V   Other   44           C√¥te d‚ÄôIvoire   2PV16N   \n",
       "2   0336-88-6412  EO571D   Other   34                 Bahamas   9WK73L   \n",
       "\n",
       "     category   views   likes  video_length  \n",
       "0        News   63950   45996            38  \n",
       "1  Technology  200516  144355           106  \n",
       "2        News  181915   59220            74  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66935588",
   "metadata": {},
   "source": [
    "You will train your retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding you will use:\n",
    "- `user_id`: ID of a user.\n",
    "- `gender`: Gender of a user.\n",
    "- `age`: age of a user.\n",
    "- `country`: country if a user.\n",
    "\n",
    "For the candidate embedding you will use:\n",
    "- `video_id`: ID of a video.\n",
    "- `category`: Video Category.\n",
    "- `views`: Number of video views.\n",
    "- `likes`: Number of video likes.\n",
    "- `video_length`: Length of video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f95d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 16:52:59.116556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-01 16:52:59.127166: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col: df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "val_ds = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0bb3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Number of users: 25986\n",
      "‚õ≥Ô∏è Number of items: 25979\n"
     ]
    }
   ],
   "source": [
    "# Query Features \n",
    "user_id_list = train_df[\"user_id\"].unique().tolist()\n",
    "countries_list = train_df[\"country\"].unique().tolist()\n",
    "gender_list = train_df[\"gender\"].unique().tolist()\n",
    "\n",
    "# Item Features\n",
    "video_id_list = train_df[\"video_id\"].unique().tolist()\n",
    "category_list = train_df[\"category\"].unique().tolist()\n",
    "\n",
    "print(f\"‚õ≥Ô∏è Number of users: {len(user_id_list)}\")\n",
    "print(f\"‚õ≥Ô∏è Number of items: {len(video_id_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c4058",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üè∞ Two Tower Model </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8db71a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63b6462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.10894044,  0.20039581,  0.37230363,  0.13125409,  0.1859128 ,\n",
       "        -0.1191321 , -0.18680353, -0.11699877, -0.03922038, -0.12373803,\n",
       "        -0.13764858,  0.01167573,  0.28114206,  0.08604892,  0.02320188,\n",
       "         0.25075862]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QueryTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                self.emb_dim\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.normalized_age = Normalization(axis=None)\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.gender_tokenizer = StringLookup(\n",
    "            vocabulary=gender_list,\n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.country_tokenizer = StringLookup(\n",
    "            vocabulary=countries_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gender_embedding = tf.one_hot(\n",
    "            self.gender_tokenizer(inputs[\"gender\"]),\n",
    "            len(gender_list),\n",
    "        )\n",
    "        \n",
    "        country_embedding = tf.one_hot(\n",
    "            self.country_tokenizer(inputs[\"country\"]),\n",
    "            len(countries_list),\n",
    "        )\n",
    "        \n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            gender_embedding,\n",
    "            country_embedding,\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "query_model = QueryTower()\n",
    "\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_df = train_df[QUERY_FEATURES]\n",
    "query_ds = df_to_ds(query_df).batch(1)\n",
    "query_model(next(iter(query_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04965563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ -8337.219 ,    271.7439,   6766.8276,  -5961.2393,   4387.9194,\n",
       "         -2594.7898,   -959.5883,  11187.032 ,  -5418.3667,   3178.5222,\n",
       "           530.5153,  16850.271 ,  -1287.1066,  -2689.3015, -12817.958 ,\n",
       "          7989.92  ]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.video_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=video_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(video_id_list) + 1,\n",
    "                self.emb_dim,\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.category_tokenizer = StringLookup(\n",
    "            vocabulary=category_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.normalized_views = Normalization(axis=None)\n",
    "        self.normalized_likes = Normalization(axis=None)\n",
    "        self.normalized_video_length = Normalization(axis=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        category_embedding = tf.one_hot(\n",
    "            self.category_tokenizer(inputs[\"category\"]),\n",
    "            len(category_list),\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.video_embedding(inputs[\"video_id\"]),\n",
    "            category_embedding,\n",
    "            tf.reshape(self.normalized_views(inputs[\"views\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"likes\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"video_length\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "item_model = ItemTower()\n",
    "\n",
    "item_df = train_df[CANDIDATE_FEATURES]\n",
    "item_df.drop_duplicates(subset=\"video_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)\n",
    "\n",
    "item_model(next(iter(item_ds.batch(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, query_model, item_model):\n",
    "        super().__init__()\n",
    "        self.query_model = query_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.query_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(\n",
    "                user_embeddings, \n",
    "                item_embeddings,\n",
    "                compute_metrics=False,\n",
    "            )\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.query_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(\n",
    "            user_embeddings, \n",
    "            item_embeddings,\n",
    "            compute_metrics=False,\n",
    "        )\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf66678",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27\">üèÉüèª‚Äç‚ôÇÔ∏è Model Training </span>\n",
    "\n",
    "You'll train our model using the AdamW optimizer, which applies weight regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e96e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TwoTowerModel with the specified query_model and item_model\n",
    "model = TwoTowerModel(query_model, item_model)\n",
    "\n",
    "# Define an optimizer using AdamW with a learning rate of 0.01\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    weight_decay=0.001, \n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "# Compile the model using the specified optimizer\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46ea848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "395/395 [==============================] - 27s 62ms/step - loss: 228725.1049 - regularization_loss: 0.0000e+00 - total_loss: 228725.1049 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4195.9941 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4195.9941\n",
      "Epoch 2/5\n",
      "395/395 [==============================] - 25s 62ms/step - loss: 15967.3948 - regularization_loss: 0.0000e+00 - total_loss: 15967.3948 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4194.6382 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4194.6382\n",
      "Epoch 3/5\n",
      "395/395 [==============================] - 24s 62ms/step - loss: 15596.5589 - regularization_loss: 0.0000e+00 - total_loss: 15596.5589 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4195.6143 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4195.6143\n",
      "Epoch 4/5\n",
      "395/395 [==============================] - 25s 63ms/step - loss: 15594.8566 - regularization_loss: 0.0000e+00 - total_loss: 15594.8566 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4196.0293 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4196.0293\n",
      "Epoch 5/5\n",
      "395/395 [==============================] - 1666s 4s/step - loss: 15701.5888 - regularization_loss: 0.0000e+00 - total_loss: 15701.5888 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4233.3628 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4233.3628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6cdde07be0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb20b1e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Upload Model to Model Registry </span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aac5bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e3fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModelModule(tf.Module):\n",
    "    def __init__(self, query_model):\n",
    "        self.query_model = query_model\n",
    "\n",
    "    @tf.function()\n",
    "    def compute_emb(self, instances):\n",
    "        query_emb = self.query_model(instances)\n",
    "        return {\n",
    "            \"user_id\": instances[\"user_id\"],\n",
    "            \"gender\": instances[\"gender\"],\n",
    "            \"age\": instances[\"age\"],\n",
    "            \"country\": instances[\"country\"],\n",
    "            \"query_emb\": query_emb,\n",
    "        }\n",
    "\n",
    "# wrap query_model:   query_model -> query_model_module\n",
    "query_model = QueryModelModule(model.query_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49a54c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 17:22:37,692 INFO: Function `compute_emb` contains input name(s) table_handle, 16213, resource with unsupported characters which will be renamed to query_tower_sequential_string_lookup_none_lookup_lookuptablefindv2_table_handle, query_tower_sequential_embedding_embedding_lookup_16213, query_tower_sequential_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:tensorflow:Assets written to: query_model/assets\n",
      "2024-10-01 17:22:42,016 INFO: Assets written to: query_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Define the input specifications for the instances\n",
    "instances_spec = {\n",
    "    'user_id': tf.TensorSpec(shape=(None,), dtype=tf.string, name='user_id'),   # Specification for user IDs\n",
    "    'gender': tf.TensorSpec(shape=(None,), dtype=tf.string, name='gender'),     # Specification for gender\n",
    "    'country': tf.TensorSpec(shape=(None,), dtype=tf.string, name='country'),    # Specification for country\n",
    "    'age': tf.TensorSpec(shape=(None,), dtype=tf.int64, name='age'),              # Specification for age\n",
    "}\n",
    "\n",
    "# Get the concrete function for the query_model's compute_emb function using the specified input signatures\n",
    "signatures = query_model.compute_emb.get_concrete_function(instances_spec)\n",
    "\n",
    "# Save the query_model along with the concrete function signatures\n",
    "tf.saved_model.save(\n",
    "    query_model,           # The model to save\n",
    "    \"query_model\",         # Path to save the model\n",
    "    signatures=signatures, # Concrete function signatures to include\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ed39777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f6ccc452050>, because it is not built.\n",
      "2024-10-01 17:22:42,632 WARNING: Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f6ccc452050>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f6cf54f64d0>, because it is not built.\n",
      "2024-10-01 17:22:42,635 WARNING: Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f6cf54f64d0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: candidate_model/assets\n",
      "2024-10-01 17:22:45,419 INFO: Assets written to: candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model.item_model,    # The model to save\n",
    "    \"candidate_model\",   # Path to save the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baa9ce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'columnar_schema': [{'name': 'user_id', 'type': 'object'},\n",
       "   {'name': 'gender', 'type': 'object'},\n",
       "   {'name': 'age', 'type': 'int64'},\n",
       "   {'name': 'country', 'type': 'object'}]},\n",
       " 'output_schema': {'tensor_schema': [{'name': 'query_embedding',\n",
       "    'shape': '[16]',\n",
       "    'type': 'float32'}]}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Infer input schema from data.\n",
    "query_model_input_schema = Schema(query_df)\n",
    "\n",
    "# Manually specify output schema.\n",
    "query_model_output_schema = Schema([{\n",
    "    \"name\": \"query_embedding\",\n",
    "    \"type\": \"float32\",\n",
    "    \"shape\": [EMB_DIM],\n",
    "}])\n",
    "\n",
    "query_model_schema = ModelSchema(\n",
    "    input_schema=query_model_input_schema,\n",
    "    output_schema=query_model_output_schema,\n",
    ")\n",
    "\n",
    "query_model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "013612bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f4925104244389ae6bcb6852d54b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee6f444858c4786b051ab8211fcff41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/562094 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dc638e462f461da21b116e6ee637fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/55 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7272cda15a804bfd9e4c092b34b83fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/576 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd702008eec64446892f6141ca644c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1688053 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839fb96bde36454b8ee0cdaacaaf5fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/78 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b049c6ae5034f53b59bf6749c52cceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/484 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/17565/models/query_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'query_model', version: 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a query example from the query DataFrame\n",
    "query_example = query_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the query_model in the Model Registry \n",
    "mr_query_model = mr.tensorflow.create_model(\n",
    "    name=\"query_model\",                                           # Name of the model\n",
    "    description=\"Model that generates query embeddings from user features\",  # Description of the model\n",
    "    input_example=query_example,                                  # Example input for the model\n",
    "    model_schema=query_model_schema,                              # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the query_model to the Model Registry\n",
    "mr_query_model.save(\"query_model\")                                # Path to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4535c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa755ed1ea554af19df8e5353bd0aa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684fc205afb8445484ed0d2d3fa38900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/527309 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf1fdfeb57447afb37c2134998977c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/57 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b2c9fbcc884c29a9fd9288c1b9793b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/562 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee37fc77ab484dfb97a30a5bc257cc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1671587 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b654de78e64a2e84003e44c35d15ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/102 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fde171bb474959b82ad19e3d03cdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/563 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/17565/models/candidate_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'candidate_model', version: 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input schema for the candidate_model based on item_df\n",
    "candidate_model_input_schema = Schema(item_df)\n",
    "\n",
    "# Define the output schema for the candidate_model, specifying the shape and type of the output\n",
    "candidate_model_output_schema = Schema([{\n",
    "    \"name\": \"candidate_embedding\",   # Name of the output feature\n",
    "    \"type\": \"float32\",               # Data type of the output feature\n",
    "    \"shape\": [EMB_DIM],              # Shape of the output feature\n",
    "}])\n",
    "\n",
    "# Combine the input and output schemas to create the overall model schema for the candidate_model\n",
    "candidate_model_schema = ModelSchema(\n",
    "    input_schema=candidate_model_input_schema,    # Input schema for the model\n",
    "    output_schema=candidate_model_output_schema,  # Output schema for the model\n",
    ")\n",
    "\n",
    "# Sample a candidate example from the item DataFrame\n",
    "candidate_example = item_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the candidate_model in the Model Registry\n",
    "mr_candidate_model = mr.tensorflow.create_model(\n",
    "    name=\"candidate_model\",                                        # Name of the model\n",
    "    description=\"Model that generates candidate embeddings from video features\",  # Description of the model\n",
    "    input_example=candidate_example,                              # Example input for the model\n",
    "    model_schema=candidate_model_schema,                          # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the candidate_model to the Model Registry\n",
    "mr_candidate_model.save(\"candidate_model\")                        # Path to save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e0ba1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf7579-492f-4dcd-8071-a6062b6e0262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

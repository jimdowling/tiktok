{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f53a397",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üß¨ Train Retrieval Model </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa182c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d80acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09283b4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b4ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://snurran.hops.works/p/11383\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261b352",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üî™ Feature Selection </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c149d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_fg = fs.get_feature_group(\n",
    "    name=\"users\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "videos_fg = fs.get_feature_group(\n",
    "    name=\"videos\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "interactions_fg = fs.get_feature_group(\n",
    "    name=\"interactions\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c14e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "272dc061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>interaction_type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>watch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9035-15-2410</td>\n",
       "      <td>like</td>\n",
       "      <td>WA546S</td>\n",
       "      <td>3EL60S</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id interaction_type user_id video_id  watch_time\n",
       "0   9035-15-2410             like  WA546S   3EL60S         206"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "obs = pd.DataFrame(\n",
    "    [[generic.person.identifier(mask='####-##-####'), 'like', 'WA546S', '3EL60S', 206]],\n",
    "    columns=['interaction_id', 'interaction_type', 'user_id', 'video_id', 'watch_time']\n",
    ")\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c2fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 15:29:44,878 INFO: \t7 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://snurran.hops.works/p/11383/fs/11331/fg/12303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edd50b639154848802285d9547e5f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: interactions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://snurran.hops.works/p/11383/jobs/named/interactions_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f23cd356110>,\n",
       " {\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.15.12\",\n",
       "     \"expectation_suite_name\": \"interactions_data_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_time\": \"2024-04-19T15:29:44.878362+00:00\",\n",
       "       \"run_name\": null\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"a63410e2-fe61-11ee-a9f8-964546f6b095\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20240419T152944.878315Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.15.12\"\n",
       "     }\n",
       "   },\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": 0,\n",
       "         \"missing_percent\": 0.0,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"unexpected_percent_nonmissing\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"watch_time\",\n",
       "           \"min_value\": 0\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9231\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"watch_time\"\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9227\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"interaction_type\"\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9228\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"observed_value\": [\n",
       "           \"like\"\n",
       "         ],\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"interaction_type\",\n",
       "           \"value_set\": [\n",
       "             \"like\",\n",
       "             \"dislike\",\n",
       "             \"view\",\n",
       "             \"comment\",\n",
       "             \"share\",\n",
       "             \"skip\"\n",
       "           ]\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_distinct_values_to_be_in_set\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9233\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"video_id\"\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9229\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"user_id\"\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9232\n",
       "         }\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"result\": {\n",
       "         \"element_count\": 1,\n",
       "         \"unexpected_count\": 0,\n",
       "         \"unexpected_percent\": 0.0,\n",
       "         \"unexpected_percent_total\": 0.0,\n",
       "         \"partial_unexpected_list\": []\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2024-04-19T03:29:44.000878Z\"\n",
       "       },\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"interaction_id\"\n",
       "         },\n",
       "         \"expectation_type\": \"expect_column_values_to_not_be_null\",\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 9230\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"success\": true,\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 7,\n",
       "     \"successful_expectations\": 7,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "interactions_fg.insert(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a22d99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d72398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FEATURES = [\"user_id\", \"gender\", \"age\", \"country\"]\n",
    "CANDIDATE_FEATURES = [\"video_id\", \"category\", \"views\", \"likes\", \"video_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f091291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (39.67s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2877-12-0444</td>\n",
       "      <td>RG876M</td>\n",
       "      <td>Female</td>\n",
       "      <td>76</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>6ZY07Y</td>\n",
       "      <td>News</td>\n",
       "      <td>192408</td>\n",
       "      <td>91932</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4380-37-7971</td>\n",
       "      <td>YU710V</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>5ZY75O</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7275</td>\n",
       "      <td>5936</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3714-23-7897</td>\n",
       "      <td>IQ911P</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>6NE41R</td>\n",
       "      <td>Dance</td>\n",
       "      <td>66149</td>\n",
       "      <td>45789</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8380-73-5772</td>\n",
       "      <td>BB023A</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>2OL92N</td>\n",
       "      <td>Technology</td>\n",
       "      <td>26029</td>\n",
       "      <td>2383</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7047-00-6140</td>\n",
       "      <td>KX410C</td>\n",
       "      <td>Other</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0MH71C</td>\n",
       "      <td>News</td>\n",
       "      <td>358125</td>\n",
       "      <td>172911</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age       country video_id    category  \\\n",
       "0   2877-12-0444  RG876M  Female   76  South Africa   6ZY07Y        News   \n",
       "1   4380-37-7971  YU710V  Female   59        Gambia   5ZY75O      Comedy   \n",
       "2   3714-23-7897  IQ911P    Male   35         Sudan   6NE41R       Dance   \n",
       "3   8380-73-5772  BB023A    Male   32        Cyprus   2OL92N  Technology   \n",
       "4   7047-00-6140  KX410C   Other   33   Afghanistan   0MH71C        News   \n",
       "\n",
       "    views   likes  video_length  \n",
       "0  192408   91932           113  \n",
       "1    7275    5936           171  \n",
       "2   66149   45789           238  \n",
       "3   26029    2383           113  \n",
       "4  358125  172911           220  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for training data\n",
    "selected_features = interactions_fg.select([\"interaction_id\"])\\\n",
    "    .join(users_fg.select(QUERY_FEATURES), on=\"user_id\")\\\n",
    "    .join(videos_fg.select(CANDIDATE_FEATURES), on=\"video_id\")\n",
    "\n",
    "# Uncomment this if you would like to view your selected features\n",
    "selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707f44",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af97a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='retrieval',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1dc1f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437f3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (42.06s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: Incremented version to `7`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4380-37-7971</td>\n",
       "      <td>YU710V</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>5ZY75O</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7275</td>\n",
       "      <td>5936</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3714-23-7897</td>\n",
       "      <td>IQ911P</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>6NE41R</td>\n",
       "      <td>Dance</td>\n",
       "      <td>66149</td>\n",
       "      <td>45789</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7047-00-6140</td>\n",
       "      <td>KX410C</td>\n",
       "      <td>Other</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0MH71C</td>\n",
       "      <td>News</td>\n",
       "      <td>358125</td>\n",
       "      <td>172911</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age      country video_id category   views  \\\n",
       "1   4380-37-7971  YU710V  Female   59       Gambia   5ZY75O   Comedy    7275   \n",
       "2   3714-23-7897  IQ911P    Male   35        Sudan   6NE41R    Dance   66149   \n",
       "4   7047-00-6140  KX410C   Other   33  Afghanistan   0MH71C     News  358125   \n",
       "\n",
       "    likes  video_length  \n",
       "1    5936           171  \n",
       "2   45789           238  \n",
       "4  172911           220  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66935588",
   "metadata": {},
   "source": [
    "You will train your retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding you will use:\n",
    "- `user_id`: ID of a user.\n",
    "- `gender`: Gender of a user.\n",
    "- `age`: age of a user.\n",
    "- `country`: country if a user.\n",
    "\n",
    "For the candidate embedding you will use:\n",
    "- `video_id`: ID of a video.\n",
    "- `category`: Video Category.\n",
    "- `views`: Number of video views.\n",
    "- `likes`: Number of video likes.\n",
    "- `video_length`: Length of video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f95d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col: df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "val_ds = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0bb3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Number of users: 24983\n",
      "‚õ≥Ô∏è Number of items: 24990\n"
     ]
    }
   ],
   "source": [
    "# Query Features \n",
    "user_id_list = train_df[\"user_id\"].unique().tolist()\n",
    "countries_list = train_df[\"country\"].unique().tolist()\n",
    "gender_list = train_df[\"gender\"].unique().tolist()\n",
    "\n",
    "# Item Features\n",
    "video_id_list = train_df[\"video_id\"].unique().tolist()\n",
    "category_list = train_df[\"category\"].unique().tolist()\n",
    "\n",
    "print(f\"‚õ≥Ô∏è Number of users: {len(user_id_list)}\")\n",
    "print(f\"‚õ≥Ô∏è Number of items: {len(video_id_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c4058",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üè∞ Two Tower Model </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db71a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b6462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-0.07137153,  0.25015256, -0.20719832,  0.10795874, -0.04775844,\n",
       "        -0.17112827, -0.25529203,  0.14370468,  0.20744579, -0.05836441,\n",
       "        -0.05365835,  0.07151634, -0.0790488 ,  0.01260526,  0.19363274,\n",
       "        -0.04510418]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QueryTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                self.emb_dim\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.normalized_age = Normalization(axis=None)\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.gender_tokenizer = StringLookup(\n",
    "            vocabulary=gender_list,\n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.country_tokenizer = StringLookup(\n",
    "            vocabulary=countries_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gender_embedding = tf.one_hot(\n",
    "            self.gender_tokenizer(inputs[\"gender\"]),\n",
    "            len(gender_list),\n",
    "        )\n",
    "        \n",
    "        country_embedding = tf.one_hot(\n",
    "            self.country_tokenizer(inputs[\"country\"]),\n",
    "            len(countries_list),\n",
    "        )\n",
    "        \n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            gender_embedding,\n",
    "            country_embedding,\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "query_model = QueryTower()\n",
    "\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_df = train_df[QUERY_FEATURES]\n",
    "query_ds = df_to_ds(query_df).batch(1)\n",
    "query_model(next(iter(query_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04965563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-1506.157  , -1316.9346 ,   110.54877,  1466.5878 , -1651.4055 ,\n",
       "         -585.2615 ,   382.82886,  1285.9456 , -2920.3616 , -2068.8064 ,\n",
       "          592.77454,  -448.13715,  -584.4979 ,   910.5513 ,  -813.92737,\n",
       "         1641.4902 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.video_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=video_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(video_id_list) + 1,\n",
    "                self.emb_dim,\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.category_tokenizer = StringLookup(\n",
    "            vocabulary=category_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.normalized_views = Normalization(axis=None)\n",
    "        self.normalized_likes = Normalization(axis=None)\n",
    "        self.normalized_video_length = Normalization(axis=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        category_embedding = tf.one_hot(\n",
    "            self.category_tokenizer(inputs[\"category\"]),\n",
    "            len(category_list),\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.video_embedding(inputs[\"video_id\"]),\n",
    "            category_embedding,\n",
    "            tf.reshape(self.normalized_views(inputs[\"views\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"likes\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"video_length\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "item_model = ItemTower()\n",
    "\n",
    "item_df = train_df[CANDIDATE_FEATURES]\n",
    "item_df.drop_duplicates(subset=\"video_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)\n",
    "\n",
    "item_model(next(iter(item_ds.batch(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, query_model, item_model):\n",
    "        super().__init__()\n",
    "        self.query_model = query_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.query_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(\n",
    "                user_embeddings, \n",
    "                item_embeddings,\n",
    "                compute_metrics=False,\n",
    "            )\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.query_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(\n",
    "            user_embeddings, \n",
    "            item_embeddings,\n",
    "            compute_metrics=False,\n",
    "        )\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf66678",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27\">üèÉüèª‚Äç‚ôÇÔ∏è Model Training </span>\n",
    "\n",
    "You'll train our model using the AdamW optimizer, which applies weight regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TwoTowerModel with the specified query_model and item_model\n",
    "model = TwoTowerModel(query_model, item_model)\n",
    "\n",
    "# Define an optimizer using AdamW with a learning rate of 0.01\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    weight_decay=0.001, \n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "# Compile the model using the specified optimizer\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ea848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 23s 53ms/step - loss: 532928.6647 - regularization_loss: 0.0000e+00 - total_loss: 532928.6647 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12652.2236 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12652.2236\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 15611.9873 - regularization_loss: 0.0000e+00 - total_loss: 15611.9873 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12617.4121 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12617.4121\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 15602.0058 - regularization_loss: 0.0000e+00 - total_loss: 15602.0058 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12611.6748 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12611.6748\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 15600.5854 - regularization_loss: 0.0000e+00 - total_loss: 15600.5854 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12617.7461 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12617.7461\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 132830.5639 - regularization_loss: 0.0000e+00 - total_loss: 132830.5639 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12633.5986 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12633.5986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5241f55750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb20b1e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Upload Model to Model Registry </span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac5bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e3fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModelModule(tf.Module):\n",
    "    def __init__(self, query_model):\n",
    "        self.query_model = query_model\n",
    "\n",
    "    @tf.function()\n",
    "    def compute_emb(self, instances):\n",
    "        query_emb = self.query_model(instances)\n",
    "        return {\n",
    "            \"user_id\": instances[\"user_id\"],\n",
    "            \"gender\": instances[\"gender\"],\n",
    "            \"age\": instances[\"age\"],\n",
    "            \"country\": instances[\"country\"],\n",
    "            \"query_emb\": query_emb,\n",
    "        }\n",
    "\n",
    "# wrap query_model:   query_model -> query_model_module\n",
    "query_model = QueryModelModule(model.query_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a54c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-04 08:47:51,434 INFO: Function `compute_emb` contains input name(s) table_handle, 15911, resource with unsupported characters which will be renamed to query_tower_sequential_string_lookup_none_lookup_lookuptablefindv2_table_handle, query_tower_sequential_embedding_embedding_lookup_15911, query_tower_sequential_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "2024-04-04 08:47:56,650 INFO: Assets written to: query_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Define the input specifications for the instances\n",
    "instances_spec = {\n",
    "    'user_id': tf.TensorSpec(shape=(None,), dtype=tf.string, name='user_id'),   # Specification for user IDs\n",
    "    'gender': tf.TensorSpec(shape=(None,), dtype=tf.string, name='gender'),     # Specification for gender\n",
    "    'country': tf.TensorSpec(shape=(None,), dtype=tf.string, name='country'),    # Specification for country\n",
    "    'age': tf.TensorSpec(shape=(None,), dtype=tf.int64, name='age'),              # Specification for age\n",
    "}\n",
    "\n",
    "# Get the concrete function for the query_model's compute_emb function using the specified input signatures\n",
    "signatures = query_model.compute_emb.get_concrete_function(instances_spec)\n",
    "\n",
    "# Save the query_model along with the concrete function signatures\n",
    "tf.saved_model.save(\n",
    "    query_model,           # The model to save\n",
    "    \"query_model\",         # Path to save the model\n",
    "    signatures=signatures, # Concrete function signatures to include\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ed39777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-04 08:47:58,497 WARNING: Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f523adb3190>, because it is not built.\n",
      "2024-04-04 08:47:58,497 WARNING: Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f523adb3af0>, because it is not built.\n",
      "2024-04-04 08:48:02,972 INFO: Assets written to: candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model.item_model,    # The model to save\n",
    "    \"candidate_model\",   # Path to save the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baa9ce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'columnar_schema': [{'name': 'user_id', 'type': 'object'},\n",
       "   {'name': 'gender', 'type': 'object'},\n",
       "   {'name': 'age', 'type': 'int64'},\n",
       "   {'name': 'country', 'type': 'object'}]},\n",
       " 'output_schema': {'tensor_schema': [{'name': 'query_embedding',\n",
       "    'shape': '[16]',\n",
       "    'type': 'float32'}]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Infer input schema from data.\n",
    "query_model_input_schema = Schema(query_df)\n",
    "\n",
    "# Manually specify output schema.\n",
    "query_model_output_schema = Schema([{\n",
    "    \"name\": \"query_embedding\",\n",
    "    \"type\": \"float32\",\n",
    "    \"shape\": [EMB_DIM],\n",
    "}])\n",
    "\n",
    "query_model_schema = ModelSchema(\n",
    "    input_schema=query_model_input_schema,\n",
    "    output_schema=query_model_output_schema,\n",
    ")\n",
    "\n",
    "query_model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "013612bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241faed9838f4161b06b49fde112344b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://snurran.hops.works/p/11383/models/query_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'query_model', version: 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a query example from the query DataFrame\n",
    "query_example = query_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the query_model in the Model Registry \n",
    "mr_query_model = mr.tensorflow.create_model(\n",
    "    name=\"query_model\",                                           # Name of the model\n",
    "    description=\"Model that generates query embeddings from user features\",  # Description of the model\n",
    "    input_example=query_example,                                  # Example input for the model\n",
    "    model_schema=query_model_schema,                              # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the query_model to the Model Registry\n",
    "mr_query_model.save(\"query_model\")                                # Path to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4535c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1048efdf1c1f45f3ac40b4cb39ee306c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://snurran.hops.works/p/11383/models/candidate_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'candidate_model', version: 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input schema for the candidate_model based on item_df\n",
    "candidate_model_input_schema = Schema(item_df)\n",
    "\n",
    "# Define the output schema for the candidate_model, specifying the shape and type of the output\n",
    "candidate_model_output_schema = Schema([{\n",
    "    \"name\": \"candidate_embedding\",   # Name of the output feature\n",
    "    \"type\": \"float32\",               # Data type of the output feature\n",
    "    \"shape\": [EMB_DIM],              # Shape of the output feature\n",
    "}])\n",
    "\n",
    "# Combine the input and output schemas to create the overall model schema for the candidate_model\n",
    "candidate_model_schema = ModelSchema(\n",
    "    input_schema=candidate_model_input_schema,    # Input schema for the model\n",
    "    output_schema=candidate_model_output_schema,  # Output schema for the model\n",
    ")\n",
    "\n",
    "# Sample a candidate example from the item DataFrame\n",
    "candidate_example = item_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the candidate_model in the Model Registry\n",
    "mr_candidate_model = mr.tensorflow.create_model(\n",
    "    name=\"candidate_model\",                                        # Name of the model\n",
    "    description=\"Model that generates candidate embeddings from video features\",  # Description of the model\n",
    "    input_example=candidate_example,                              # Example input for the model\n",
    "    model_schema=candidate_model_schema,                          # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the candidate_model to the Model Registry\n",
    "mr_candidate_model.save(\"candidate_model\")                        # Path to save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e0ba1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
